---
title: "STAT151A Homework 1: Due Jan 26th"
author: Your name here
number-sections: true 
number-depth: 1 
---

{{< include ../macros.tex >}}



# Simple regression in matrix form

Consider the simple linear model
$y_n = \beta_0 + \beta_1 z_n + \res_n$.

Let $\ybar:= \meann \y_n$ and
$\zbar:= \meann \z_n$. Recall that the ordinary least
squares estimates are given by 
$$
\begin{aligned}
    \bhat_1 = \frac{\meann(\z_n - \zbar) (\y- \ybar)}{\meann(\z_n - \zbar)^2}
    \quad\textrm{and}\quad
    \bhat_0 = \ybar- \bhat_1 \zbar.
\end{aligned}
$$

#### (a)

Write the set of equations

$$
y_n = \beta_0 + \beta_1 z_n + \res_n
$$

for $n \in \{1, \ldots, N\}$ in matrix form.
That is, let $\X$ denote an $N \times
2$ matrix, $\Y$ and $\resv$ denote $N \times 1$ matrices, 
$\bv= (\beta_0, \beta_1)^\trans$, and 
express the matrices $\Y$, $\X$, and $\resv$
in terms of the scalars $\y_n$, $\z_m$, and $\res_n$
so that $\Y= \X\bv+ \resv$ is equivalent to the set of
regression equations.


#### (b)

Define 
$$
\begin{aligned}
    \overline{zz} := \meann \z_n^2
    \quad\textrm{and}\quad
    \overline{zy} := \meann \z_n \y_n
\end{aligned}
$$ 

Write an explict expressions for $\X^\trans\X$,
$\X^\trans\Y$, and $\left(\X^\trans\X\right)^{-1}$, all in terms of $\ybar$,
$\zbar$, $\overline{zz}$, $\overline{zy}$, and $N$. Verify that the inverse is
correct by direct multiplication.

#### (c)

Compute $(\X^\trans\X)^{-1} \X^\trans\Y$. Show
that the first row is equal to $\bhat_0$ and the second row is
equal to $\bhat_1$ as given by the ordinary least squares
formula in the problem statement above.





# Mean zero residuals.

Consider the model $\y_n = \beta \z_n + \res_n$.  Let $\bhat$ denote
the least squares estimator and $\reshat_n = \y_n - \bhat \z_n$.

#### (a)

Suppose $\z_n$ is not a constant.  Is it necessarily the case that
$\meann \reshat_n = 0$?  Prove your answer.


#### (b)

Suppose $\z_n$ is a constant, but $\z_n \equiv 5$ for every $n \in \{1, \ldots, N\}$.
Is it necessarily the case that $\meann \reshat_n = 0$?  Prove your answer.


#### (c)

Now the model $\y_n = \beta_1 \z_{n1} + \beta_2 \z_{n2} + \res_n$.
Suppose that $\z_{n1} = 1$ is $n$ is even, and is $0$ otherwise.
Similarly, suppose that $\z_{n2} = 1$ is $n$ is odd, and is
$0$ otherwise.  Let $N$ be even.  Is it necessarily the case that 
$\meann \reshat_n = 0$? Prove your answer.







# Inner products and covariances


Let $\zv = (\z_1, \ldots, \z_N)$ and $\yv = (\y_1, \ldots, \y_N)$.
Let $\X$ denote an $N \times P$ matrix whose $n$--th row is the
transpose of the $P$-vector $\xv_n^\trans$.  

(Note: this question involves limits of random variables,
and there are many distinct ways that random variables can
converge to limits.  If 
you're familiar with these different modes of probabilisitic convergence,
feel free to state what mode of convergence applies, but if you are
not, don't worry --- modes of convergence will not matter much
for this class, and you can state your result heuristically.)

For a set of quantities (numbers, vectors, pairs of vectors, etc),
the "empirical distribution" over that set refers to drawing an
element with replacement from the set with equal probability given
to each entry.  For example, if $\mathcal{Z}'$ is a drawn
from the empirical distribution over the set $\{z_1, \ldots, \z_N \}$,
then $\prob{}{\mathcal{Z}' = \z_n} = 1/N$ for each $n$.  Similarly, if
$(\mathcal{Z}', \mathcal{Y}')$ is drawn from the empirical distribution
over the pairs $\{(\z_1, \y_1), \ldots, (\z_N, \y_N)\}$, then
$\prob{}{(\mathcal{Z}', \mathcal{Y}') = (\z_n, \y_n)} = 1/N$ for all $n$.

(Hint: it may help to recall that the bootstrap uses draws
from the empirical distribution, and that, in the empirical distribution,
the elements of the set are fixed and not random.)

#### (a)

Let $(\mathcal{Z}', \mathcal{Y}')$ denote a draw from the empirical distribution
over the set $\{(\y_1, \z_1), \ldots, (\y_N, \z_N)\}$.

Prove that $\frac{1}{N} \zv^\trans \yv = \expect{}{\mathcal{Z}' \mathcal{Y}'}$.
Then prove that
$\frac{1}{N} \onev^\trans \zv = \expect{}{\mathcal{Z}'}$ as a special case.


#### (b)

Now suppose that the entries of $\zv$ are independent and identically
distributed (IID) realizations of the random variable $\mathcal{Z}$, and that
the entries of $\yv$ are similarly IID realizations of a random variable
$\mathcal{Y}$.  Assuming that $\expect{}{|\mathcal{Z}|} < \infty$ and
$\expect{}{|\mathcal{Y}|} < \infty$, prove that

$$
\frac{1}{N} \zv^\trans \yv \rightarrow
    \expect{}{\mathcal{Z} \mathcal{Y}}
    \textrm{ as }N \rightarrow \infty
$$

(Hint: don't prove this from scratch, appeal to a probability theorem.)


#### (c)

Using only inner products involving $\yv$, $\zv$, and $\onev$,
write an expression for $\cov{}{\mathcal{Y}', \mathcal{Z}'}$.  Prove
that the expression converges with probability one to $\cov{}{\mathcal{Y}, \mathcal{Z}}$.
(Hint: again, use your previous results and a theorem from probability.)


#### (d)

Now, let $(\mathcal{X}', \mathcal{Y}')$ denote a draw 
from the empirical distribution over $\{(\x_1, \y_1), \ldots, (\x_N, \y_N) \}$.
(Recall that the vector $\x_n$ is a length--$P$ column vector, and $\x_n^\trans$ is
the $n$--th row of the matrix $\X$.)

$$
\begin{align*}
\frac{1}{N} \X^\trans \X = \expect{}{\mathcal{X}' \mathcal{X}'^\trans}
\quad\textrm{and}\quad
\frac{1}{N} \X^\trans \y = \expect{}{\mathcal{X}' \mathcal{Y}'}.
\end{align*}
$$


#### (e)

Now, suppose that rows of $\X$ are IID realizations of the random
$P$--vector $\mathcal{X}$, and that $\expect{}{|\mathcal{X}_p|} < \infty$
for each $p \in \{ 1, \ldots, P \}$.  Assume, as above, that
$\expect{}{|\mathcal{Y}|} < \infty$.

Prove that, as $N \rightarrow \infty$,

$$
\frac{1}{N} \X^\trans \X \rightarrow
    \expect{}{\mathcal{X} \mathcal{X}^\trans}
\quad\textrm{and}\quad
\frac{1}{N} \X^\trans \Y \rightarrow
    \expect{}{\mathcal{X} \mathcal{Y}},
$$

where both limits are with probability one.


#### (f)

Now assume that, for each $p \in \{1, \ldots, P\}$ and $q \in \{1, \ldots, P\}$,
$\expect{}{\abs{\mathcal{X}'_p} \abs{\mathcal{X}'_q} \mathcal{Y}^2} < \infty$.
Prove that, as $N \rightarrow \infty$, 

$$
\frac{1}{\sqrt{N}}
\left( \X^\trans \Y - \expect{}{\X^\trans \Y} \right) \rightarrow \mathcal{Z},
$$ 

where
$\mathcal{Z}$ is a multivariate normal random variable.  What is the covariance of $\mathcal{Z}$?
(Hint: again, appeal to a probability theorem.)

