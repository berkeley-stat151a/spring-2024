% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{1}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={STAT151A Homework 1: Due Jan 26th},
  pdfauthor={Your name here},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{STAT151A Homework 1: Due Jan 26th}
\author{Your name here}
\date{}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[frame hidden, borderline west={3pt}{0pt}{shadecolor}, breakable, boxrule=0pt, sharp corners, interior hidden, enhanced]}{\end{tcolorbox}}\fi

\newcommand{\trans}{\intercal}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\bbr}{\mathbb{R}}
\newcommand{\bbz}{\mathbb{Z}}
\newcommand{\bbc}{\mathbb{C}}
\newcommand{\gauss}[1]{\mathcal{N}\left(#1\right)}

\newcommand{\argmin}[1]{\underset{#1}{\mathrm{argmin}}\,}
\newcommand{\projop}[1]{\underset{#1}{\mathrm{Proj}}\,}
\newcommand{\proj}[1]{\underset{#1}{\mybold{P}}}
\newcommand{\expect}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\prob}[1]{\mathbb{P}\left(#1\right)}
\newcommand{\dens}[1]{\mathit{p}\left(#1\right)}
\newcommand{\var}[1]{\mathrm{Var}\left(#1\right)}
\newcommand{\cov}[1]{\mathrm{Cov}\left(#1\right)}
\newcommand{\sumn}{\sum_{n=1}^N}
\newcommand{\meann}{\frac{1}{N} \sumn}

\newcommand{\trace}[1]{\mathrm{trace}\left(#1\right)}
\newcommand{\diag}[1]{\mathrm{Diag}\left(#1\right)}
\newcommand{\grad}[2]{\nabla_{#1} \left. #2 \right.}
\newcommand{\gradat}[3]{\nabla_{#1} \left. #2 \right|_{#3}}
\newcommand{\fracat}[3]{\left. \frac{#1}{#2} \right|_{#3}}

\newcommand{\mybold}[1]{\boldsymbol{#1}}

\newcommand{\W}{\mybold{W}}
\newcommand{\w}{w}
\newcommand{\wbar}{\bar{w}}
\newcommand{\wv}{\mybold{w}}

\newcommand{\X}{\mybold{X}}
\newcommand{\x}{x}
\newcommand{\xbar}{\bar{x}}
\newcommand{\xv}{\mybold{x}}
\newcommand{\Xcov}{\Sigmam_{\X}}

\newcommand{\Z}{\mybold{Z}}
\newcommand{\z}{z}
\newcommand{\zv}{\mybold{z}}
\newcommand{\zbar}{\bar{z}}

\newcommand{\Y}{\mybold{Y}}
\newcommand{\Yhat}{\hat{\Y}}
\newcommand{\y}{y}
\newcommand{\yv}{\mybold{y}}
\newcommand{\yhat}{\hat{\y}}
\newcommand{\ybar}{\bar{y}}

\newcommand{\res}{\varepsilon}
\newcommand{\resv}{\mybold{\res}}
\newcommand{\resvhat}{\hat{\mybold{\res}}}
\newcommand{\reshat}{\hat{\res}}

\newcommand{\betav}{\mybold{\beta}}
\newcommand{\betavhat}{\hat{\bv}}
\newcommand{\betahat}{\hat{\beta}}

\newcommand{\bv}{\mybold{\beta}}
\newcommand{\bvhat}{\hat{\bv}}
\newcommand{\bhat}{\hat{\beta}}
\newcommand{\betahat}{\hat{\beta}}

\newcommand{\alphav}{\mybold{\alpha}}
\newcommand{\alphavhat}{\hat{\av}}
\newcommand{\alphahat}{\hat{\alpha}}

\newcommand{\gv}{\mybold{\gamma}}
\newcommand{\gvhat}{\hat{\gv}}
\newcommand{\ghat}{\hat{\gamma}}

\newcommand{\hv}{\mybold{\h}}
\newcommand{\hvhat}{\hat{\hv}}
\newcommand{\hhat}{\hat{\h}}

\newcommand{\gammav}{\mybold{\gamma}}
\newcommand{\gammavhat}{\hat{\gammav}}
\newcommand{\gammahat}{\hat{\gamma}}

\newcommand{\new}{\mathrm{new}}
\newcommand{\zerov}{\mybold{0}}
\newcommand{\onev}{\mybold{1}}
\newcommand{\id}{\mybold{I}}

\newcommand{\sigmahat}{\hat{\sigma}}

\newcommand{\etav}{\mybold{\eta}}
\newcommand{\muv}{\mybold{\mu}}
\newcommand{\Sigmam}{\mybold{\Sigma}}

\newcommand{\rdom}[1]{\mathbb{R}^{#1}}

\newcommand{\RV}[1]{\tilde{#1}}

\def\A{\mybold{A}}

\def\A{\mybold{A}}
\def\av{\mybold{a}}
\def\a{a}

\def\A{\mybold{A}}

\def\S{\mybold{S}}
\def\sv{\mybold{s}}
\def\s{s}

\def\R{\mybold{R}}
\def\rv{\mybold{r}}
\def\r{r}

\def\V{\mybold{V}}
\def\vv{\mybold{v}}
\def\v{v}

\def\U{\mybold{U}}
\def\uv{\mybold{u}}
\def\u{u}

\def\Sc{\mathcal{S}}
\def\ev{\mybold{e}}

\def\Lammat{\mybold{\Lambda}}

\hypertarget{simple-regression-in-matrix-form}{%
\section{Simple regression in matrix
form}\label{simple-regression-in-matrix-form}}

Consider the simple linear model
\(y_n = \beta_0 + \beta_1 z_n + \varepsilon_n\).

Let \(\bar{y}:= \frac{1}{N} \sum_{n=1}^Ny_n\) and
\(\bar{z}:= \frac{1}{N} \sum_{n=1}^Nz_n\). Recall that the ordinary
least squares estimates are given by \[
\begin{aligned}
    \hat{\beta}_1 = \frac{\frac{1}{N} \sum_{n=1}^N(z_n - \bar{z}) (y- \bar{y})}{\frac{1}{N} \sum_{n=1}^N(z_n - \bar{z})^2}
    \quad\textrm{and}\quad
    \hat{\beta}_0 = \bar{y}- \hat{\beta}_1 \bar{z}.
\end{aligned}
\]

\hypertarget{a}{%
\paragraph{(a)}\label{a}}

Write the set of equations

\[
y_n = \beta_0 + \beta_1 z_n + \varepsilon_n
\]

for \(n \in \{1, \ldots, N\}\) in matrix form. That is, let
\(\boldsymbol{X}\) denote an \(N \times 2\) matrix, \(\boldsymbol{Y}\)
and \(\boldsymbol{\varepsilon}\) denote \(N \times 1\) matrices,
\(\boldsymbol{\beta}= (\beta_0, \beta_1)^\intercal\), and express the
matrices \(\boldsymbol{Y}\), \(\boldsymbol{X}\), and
\(\boldsymbol{\varepsilon}\) in terms of the scalars \(y_n\), \(z_m\),
and \(\varepsilon_n\) so that
\(\boldsymbol{Y}= \boldsymbol{X}\boldsymbol{\beta}+ \boldsymbol{\varepsilon}\)
is equivalent to the set of regression equations.

\textbf{Solution}:

\[
\boldsymbol{X}=
\begin{pmatrix}
1 & z_1 \\
\vdots & \vdots \\
1 & z_N 
\end{pmatrix}
\quad\quad\quad
\boldsymbol{Y}= \begin{pmatrix}
y_1 \\
\vdots \\
y_N
\end{pmatrix}
\quad\quad\quad
\boldsymbol{\varepsilon}= \begin{pmatrix}
\varepsilon_1 \\
\vdots \\
\varepsilon_N
\end{pmatrix}
\]

\hypertarget{b}{%
\paragraph{(b)}\label{b}}

Define \[
\begin{aligned}
    \overline{zz} := \frac{1}{N} \sum_{n=1}^Nz_n^2
    \quad\textrm{and}\quad
    \overline{zy} := \frac{1}{N} \sum_{n=1}^Nz_n y_n
\end{aligned}
\]

Write an explict expressions for
\(\boldsymbol{X}^\intercal\boldsymbol{X}\),
\(\boldsymbol{X}^\intercal\boldsymbol{Y}\), and
\(\left(\boldsymbol{X}^\intercal\boldsymbol{X}\right)^{-1}\), all in
terms of \(\bar{y}\), \(\bar{z}\), \(\overline{zz}\), \(\overline{zy}\),
and \(N\). Verify that the inverse is correct by direct multiplication.

\textbf{Solution}:

\[
\boldsymbol{X}^\intercal\boldsymbol{X}= 
N \begin{pmatrix}
1 & \overline{z} \\
\overline{z} & \overline{zz} \\
\end{pmatrix}
\quad\quad\quad
\boldsymbol{X}^\intercal\boldsymbol{Y}= N \begin{pmatrix}
\overline{y} \\
\overline{zy} \\
\end{pmatrix}
\quad\quad\quad
(\boldsymbol{X}^\intercal\boldsymbol{X})^{-1} = 
\frac{1}{N}
\frac{1}{\overline{zz} - \overline{z}^2}
\begin{pmatrix}
\overline{zz} & -\overline{z} \\
-\overline{z} & 1 \\
\end{pmatrix}
\]

\hypertarget{c}{%
\paragraph{(c)}\label{c}}

Compute
\((\boldsymbol{X}^\intercal\boldsymbol{X})^{-1} \boldsymbol{X}^\intercal\boldsymbol{Y}\).
Show that the first row is equal to \(\hat{\beta}_0\) and the second row
is equal to \(\hat{\beta}_1\) as given by the ordinary least squares
formula in the problem statement above.

\textbf{Solution}: Just do matrix multiplication correctly. The
calculation is also done in \href{/lectures/Lecture3.qmd}{Lecture 3}.

\hypertarget{mean-zero-residuals.}{%
\section{Mean zero residuals.}\label{mean-zero-residuals.}}

Consider the model \(y_n = \beta z_n + \varepsilon_n\). Let
\(\hat{\beta}\) denote the least squares estimator and
\(\hat{\varepsilon}_n = y_n - \hat{\beta}z_n\).

\hypertarget{a-1}{%
\paragraph{(a)}\label{a-1}}

Suppose \(z_n\) is not a constant. Is it necessarily the case that
\(\frac{1}{N} \sum_{n=1}^N\hat{\varepsilon}_n = 0\)? Prove your answer.

\textbf{Solution}: It is not. A counterexample is enough. For example,
take \(y_n = 1\), \(N\) even and \(z_n = (-1)^n\). Then
\(\hat{\beta}= \sum_{n=1}^Ny_n z_n / \sum_{n=1}^Nz_n^2 = 0\), so
\(\hat{\varepsilon}_n = 1\).

\hypertarget{b-1}{%
\paragraph{(b)}\label{b-1}}

Suppose \(z_n\) is a constant, but \(z_n \equiv 5\) for every
\(n \in \{1, \ldots, N\}\). Is it necessarily the case that
\(\frac{1}{N} \sum_{n=1}^N\hat{\varepsilon}_n = 0\)? Prove your answer.

\textbf{Solution}: Yes. You can either do the calculation directly, or
you can use the fact that
\(\boldsymbol{\varepsilon}\perp \boldsymbol{z}\).

\hypertarget{c-1}{%
\paragraph{(c)}\label{c-1}}

Now the model \(y_n = \beta_1 z_{n1} + \beta_2 z_{n2} + \varepsilon_n\).
Suppose that \(z_{n1} = 1\) is \(n\) is even, and is \(0\) otherwise.
Similarly, suppose that \(z_{n2} = 1\) is \(n\) is odd, and is \(0\)
otherwise. Let \(N\) be even. Is it necessarily the case that
\(\frac{1}{N} \sum_{n=1}^N\hat{\varepsilon}_n = 0\)? Prove your answer.

\textbf{Solution}: It is the case. The ones vector \(\boldsymbol{1}\) is
in the linear span of \(\boldsymbol{z}\) since \(z_{n1} + z_{n2} = 1\),
so \(\boldsymbol{\varepsilon}\perp \boldsymbol{1}\).

\hypertarget{inner-products-and-covariances}{%
\section{Inner products and
covariances}\label{inner-products-and-covariances}}

Let \(\boldsymbol{z}= (z_1, \ldots, z_N)\) and
\(\boldsymbol{y}= (y_1, \ldots, y_N)\). Let \(\boldsymbol{X}\) denote an
\(N \times P\) matrix whose \(n\)--th row is the transpose of the
\(P\)-vector \(\boldsymbol{x}_n^\intercal\).

(Note: this question involves limits of random variables, and there are
many distinct ways that random variables can converge to limits. If
you're familiar with these different modes of probabilisitic
convergence, feel free to state what mode of convergence applies, but if
you are not, don't worry --- modes of convergence will not matter much
for this class, and you can state your result heuristically.)

For a set of quantities (numbers, vectors, pairs of vectors, etc), the
``empirical distribution'' over that set refers to drawing an element
with replacement from the set with equal probability given to each
entry. For example, if \(\mathcal{Z}'\) is a drawn from the empirical
distribution over the set \(\{z_1, \ldots, z_N \}\), then
\(\mathbb{P}\left(\mathcal{Z}' = z_n\right) = 1/N\) for each \(n\).
Similarly, if \((\mathcal{Z}', \mathcal{Y}')\) is drawn from the
empirical distribution over the pairs
\(\{(z_1, y_1), \ldots, (z_N, y_N)\}\), then
\(\mathbb{P}\left((\mathcal{Z}', \mathcal{Y}') = (z_n, y_n)\right) = 1/N\)
for all \(n\).

(Hint: it may help to recall that the bootstrap uses draws from the
empirical distribution, and that, in the empirical distribution, the
elements of the set are fixed and not random.)

\hypertarget{a-2}{%
\paragraph{(a)}\label{a-2}}

Let \((\mathcal{Z}', \mathcal{Y}')\) denote a draw from the empirical
distribution over the set \(\{(y_1, z_1), \ldots, (y_N, z_N)\}\).

Prove that
\(\frac{1}{N} \boldsymbol{z}^\intercal\boldsymbol{y}= \mathbb{E}\left[\mathcal{Z}' \mathcal{Y}'\right]\).
Then prove that
\(\frac{1}{N} \boldsymbol{1}^\intercal\boldsymbol{z}= \mathbb{E}\left[\mathcal{Z}'\right]\)
as a special case.

\textbf{Solution}: Recognize the inner product as a sum. Then both
follow from the definition of the expectation with respect to the
empirical distribution.

\hypertarget{b-2}{%
\paragraph{(b)}\label{b-2}}

Now suppose that the entries of \(\boldsymbol{z}\) are independent and
identically distributed (IID) realizations of the random variable
\(\mathcal{Z}\), and that the entries of \(\boldsymbol{y}\) are
similarly IID realizations of a random variable \(\mathcal{Y}\).
Assuming that \(\mathbb{E}\left[|\mathcal{Z}|\right] < \infty\) and
\(\mathbb{E}\left[|\mathcal{Y}|\right] < \infty\), prove that

\[
\frac{1}{N} \boldsymbol{z}^\intercal\boldsymbol{y}\rightarrow
    \mathbb{E}\left[\mathcal{Z} \mathcal{Y}\right]
    \textrm{ as }N \rightarrow \infty
\]

(Hint: don't prove this from scratch, appeal to a probability theorem.)

\textbf{Solution}: Recognize the inner product as a sum, then appeal to
the law of large numbers (weak or strong is okay).

\hypertarget{c-2}{%
\paragraph{(c)}\label{c-2}}

Using only inner products involving \(\boldsymbol{y}\),
\(\boldsymbol{z}\), and \(\boldsymbol{1}\), write an expression for
\(\mathrm{Cov}\left(\mathcal{Y}', \mathcal{Z}'\right)\). Prove that the
expression converges with probability one to
\(\mathrm{Cov}\left(\mathcal{Y}, \mathcal{Z}\right)\). (Hint: again, use
your previous results and a theorem from probability.)

\textbf{Solution}: Using our previous results, \[
\begin{aligned}
\mathrm{Cov}\left(\mathcal{Y}', \mathcal{Z}'\right) ={}&
    \mathbb{E}\left[(\mathcal{Y}' - \mathbb{E}\left[\mathcal{Y}'\right])(\mathcal{Z}' - \mathbb{E}\left[\mathcal{Z}'\right])\right] \\
={}&
    \mathbb{E}\left[(\mathcal{Y}' - N^{-1} \boldsymbol{1}^\intercal\boldsymbol{y})(\mathcal{Z}' - N^{-1} \boldsymbol{1}^\intercal\boldsymbol{z})\right] \\
={}&
    N^{-1} (\boldsymbol{y}- N^{-1} \boldsymbol{1}^\intercal\boldsymbol{y})^\intercal(\boldsymbol{z}- N^{-1} \boldsymbol{1}^\intercal\boldsymbol{z}).
\end{aligned}
\]

\hypertarget{d}{%
\paragraph{(d)}\label{d}}

Now, let \((\mathcal{X}', \mathcal{Y}')\) denote a draw from the
empirical distribution over \(\{(x_1, y_1), \ldots, (x_N, y_N) \}\).
(Recall that the vector \(x_n\) is a length--\(P\) column vector, and
\(x_n^\intercal\) is the \(n\)--th row of the matrix
\(\boldsymbol{X}\).)

\[
\begin{aligned}
\frac{1}{N} \boldsymbol{X}^\intercal\boldsymbol{X}= \mathbb{E}\left[\mathcal{X}' \mathcal{X}'^\intercal\right]
\quad\textrm{and}\quad
\frac{1}{N} \boldsymbol{X}^\intercal y= \mathbb{E}\left[\mathcal{X}' \mathcal{Y}'\right].
\end{aligned}
\]

\textbf{Solution}: Apply the previous results componentwise.

\hypertarget{e}{%
\paragraph{(e)}\label{e}}

Now, suppose that rows of \(\boldsymbol{X}\) are IID realizations of the
random \(P\)--vector \(\mathcal{X}\), and that
\(\mathbb{E}\left[|\mathcal{X}_p|\right] < \infty\) for each
\(p \in \{ 1, \ldots, P \}\). Assume, as above, that
\(\mathbb{E}\left[|\mathcal{Y}|\right] < \infty\).

Prove that, as \(N \rightarrow \infty\),

\[
\frac{1}{N} \boldsymbol{X}^\intercal\boldsymbol{X}\rightarrow
    \mathbb{E}\left[\mathcal{X} \mathcal{X}^\intercal\right]
\quad\textrm{and}\quad
\frac{1}{N} \boldsymbol{X}^\intercal\boldsymbol{Y}\rightarrow
    \mathbb{E}\left[\mathcal{X} \mathcal{Y}\right],
\]

where both limits are with probability one.

\textbf{Solution}: Apply the previous results componentwise.

\hypertarget{f}{%
\paragraph{(f)}\label{f}}

Now assume that, for each \(p \in \{1, \ldots, P\}\) and
\(q \in \{1, \ldots, P\}\),
\(\mathbb{E}\left[\left|\mathcal{X}'_p\right| \left|\mathcal{X}'_q\right| \mathcal{Y}^2\right] < \infty\).
Prove that, as \(N \rightarrow \infty\),

\[
\frac{1}{\sqrt{N}}
\left( \boldsymbol{X}^\intercal\boldsymbol{Y}- \mathbb{E}\left[\boldsymbol{X}^\intercal\boldsymbol{Y}\right] \right) \rightarrow \mathcal{Z},
\]

where \(\mathcal{Z}\) is a multivariate normal random variable. What is
the covariance of \(\mathcal{Z}\)? (Hint: again, appeal to a probability
theorem.)

\textbf{Solution}: Appeal to the multivariate central limit theorem.



\end{document}
